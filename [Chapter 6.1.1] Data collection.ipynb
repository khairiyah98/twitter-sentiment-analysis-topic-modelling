{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"[Chapter 6.1.1] Data collection.ipynb","provenance":[{"file_id":"1TQXqIoKBSXuD__YlytjAfxWATLIhpVJQ","timestamp":1617027782624}],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"id":"y1i975zMrf0X"},"source":["# Run the pip install command below if you don't already have the library\n","!pip install git+https://github.com/JustAnotherArchivist/snscrape.git\n","\n","# Run the below command if you don't already have Pandas\n","!pip install pandas\n","!pip install numpy==1.19.3 --user\n","\n","# Imports\n","import snscrape.modules.twitter as sntwitter\n","import pandas as pd"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AuHJxqZtrf0i"},"source":["# Setting variables to be used below\n","maxTweets = 10000\n","\n","# Creating list to append tweet data to\n","tweets_list2 = []\n","\n","# Using TwitterSearchScraper to scrape data and append tweets to list\n","for i,tweet in enumerate(sntwitter.TwitterSearchScraper('coronavirus OR wuhan OR wuhanvirus OR wuhancoronavirus OR nCoV2019 OR 2019nCoV OR COVID OR SARS-COV-2 OR circuitbreaker since:2020-02-01 until:2020-09-01 near:Singapore lang:en').get_items()):\n","    if i>maxTweets:\n","        break\n","    tweets_list2.append([tweet.date, tweet.url, tweet.id, tweet.user.id, tweet.content, tweet.user.username, tweet.user.location, tweet.replyCount, tweet.retweetCount, tweet.likeCount, tweet.quoteCount, tweet.lang, tweet.retweetedTweet, tweet.quotedTweet, tweet.mentionedUsers])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1kin6oCBrf0j"},"source":["# Creating a dataframe from the tweets list above\n","tweets_df2 = pd.DataFrame(tweets_list2, columns=['Datetime', 'Tweet URL', 'Tweet Id','Tweet User Id', 'Text', 'Username', 'User Location', 'replyCount', 'retweetCount', 'likeCount', 'quoteCount', 'language', 'retweetedTweet', 'quotedTweet', 'mentionedUsers'])\n","\n","# Display first 5 entries from dataframe\n","tweets_df2.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mo0eYp_irf0k"},"source":["tweets_df3 = tweets_df2.drop_duplicates(subset='Text', keep=\"last\")\n","\n","print(tweets_df3.shape)\n","tweets_df3.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"evR1vtA0rf0k"},"source":["tweets_df3.Text.head(30)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5GHGPVnmrf0l"},"source":["# Export dataframe into a CSV\n","tweets_df3.to_csv('data/tweets_raw.csv', sep=',', index=False)"],"execution_count":null,"outputs":[]}]}